{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7xgiZcCpwnd3V6kjNCLSx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KesteHarshada87/MachineLearning/blob/main/_NaiveBayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWeHXtVzA2pe",
        "outputId": "47b75d94-6962-47b9-f681-426b39f9d597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                            message\n",
            "0   ham                   Hey, are we still meeting today?\n",
            "1  spam  Congratulations! You've won a free lottery tic...\n",
            "2   ham               Can you send me the notes for class?\n",
            "3   ham                    I will call you in the evening.\n",
            "4  spam           You won $1000 cash! Click here to claim.\n",
            "5   ham           Don't forget about the meeting tomorrow.\n",
            "6  spam              Get cheap loans now!!! Limited offer.\n",
            "7   ham              Happy Birthday! Wish you a great day.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Simple sample dataset\n",
        "data = {\n",
        "    \"label\": [\"ham\", \"spam\", \"ham\", \"ham\", \"spam\", \"ham\", \"spam\", \"ham\"],\n",
        "    \"message\": [\n",
        "        \"Hey, are we still meeting today?\",\n",
        "        \"Congratulations! You've won a free lottery ticket. Claim now!\",\n",
        "        \"Can you send me the notes for class?\",\n",
        "        \"I will call you in the evening.\",\n",
        "        \"You won $1000 cash! Click here to claim.\",\n",
        "        \"Don't forget about the meeting tomorrow.\",\n",
        "        \"Get cheap loans now!!! Limited offer.\",\n",
        "        \"Happy Birthday! Wish you a great day.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "# Initialize tools\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    # 1. Lowercase\n",
        "    text = text.lower()\n",
        "    # 2. Remove punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    # 3. Tokenize (split by space)\n",
        "    tokens = text.split()\n",
        "    # 4. Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # 5. Stemming\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "    # Join back to string\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "df[\"clean_message\"] = df[\"message\"].apply(preprocess_text)\n",
        "\n",
        "print(df[[\"message\", \"clean_message\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gFovqHwBBpK",
        "outputId": "2aa94223-9099-4346-d7a8-ecbdb221b3ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             message  \\\n",
            "0                   Hey, are we still meeting today?   \n",
            "1  Congratulations! You've won a free lottery tic...   \n",
            "2               Can you send me the notes for class?   \n",
            "3                    I will call you in the evening.   \n",
            "4           You won $1000 cash! Click here to claim.   \n",
            "5           Don't forget about the meeting tomorrow.   \n",
            "6              Get cheap loans now!!! Limited offer.   \n",
            "7              Happy Birthday! Wish you a great day.   \n",
            "\n",
            "                              clean_message  \n",
            "0                      hey still meet today  \n",
            "1  congratul youv free lotteri ticket claim  \n",
            "2                           send note class  \n",
            "3                                 call even  \n",
            "4                     1000 cash click claim  \n",
            "5                 dont forget meet tomorrow  \n",
            "6                get cheap loan limit offer  \n",
            "7             happi birthday wish great day  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Use TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the cleaned messages\n",
        "X = vectorizer.fit_transform(df[\"clean_message\"])\n",
        "\n",
        "# Labels (ham/spam)\n",
        "y = df[\"label\"]\n",
        "\n",
        "# Show feature names (words)\n",
        "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n",
        "\n",
        "# Show TF-IDF matrix shape\n",
        "print(\"TF-IDF Matrix Shape:\", X.shape)\n",
        "\n",
        "# Convert first row to dense array for illustration\n",
        "print(\"First message TF-IDF vector:\\n\", X[0].toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UAS2sOjDBQy",
        "outputId": "43ea217e-ac85-4bf8-a194-94d27c89c8d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['1000' 'birthday' 'call' 'cash' 'cheap' 'claim' 'class' 'click'\n",
            " 'congratul' 'day' 'dont' 'even' 'forget' 'free' 'get' 'great' 'happi'\n",
            " 'hey' 'limit' 'loan' 'lotteri' 'meet' 'note' 'offer' 'send' 'still'\n",
            " 'ticket' 'today' 'tomorrow' 'wish' 'youv']\n",
            "TF-IDF Matrix Shape: (8, 31)\n",
            "First message TF-IDF vector:\n",
            " [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.51970849\n",
            "  0.         0.         0.         0.43555627 0.         0.\n",
            "  0.         0.51970849 0.         0.51970849 0.         0.\n",
            "  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEvALXHDDwx8",
        "outputId": "e438ba04-645b-4a6a-f31a-d222282c33e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (6, 31)\n",
            "Testing set shape: (2, 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model trained successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmcZMuU2ESDd",
        "outputId": "5c7b9ada-f27f-4320-c452-cb0090d677c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "y_pred = nb_model.predict(X_test)\n",
        "\n",
        "print(\"Predicted labels:\", y_pred.tolist())\n",
        "print(\"Actual labels:\", y_test.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJVEurpFEgdh",
        "outputId": "898ae265-0ff9-43b2-ee7e-433509c0fb90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels: ['ham', 'ham']\n",
            "Actual labels: ['spam', 'ham']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Classification report (precision, recall, F1-score)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZGS0xQQErOX",
        "outputId": "d479a63c-2200-4a7a-822b-2fc08d8353a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.50      1.00      0.67         1\n",
            "        spam       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[\"ham\", \"spam\"])\n",
        "print(\"Confusion Matrix:\\n\", cm)\n"
      ],
      "metadata": {
        "id": "eE9MvpCiGTwb",
        "outputId": "37000c1f-6939-45cb-8974-18c647827b64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[1 0]\n",
            " [1 0]]\n"
          ]
        }
      ]
    }
  ]
}